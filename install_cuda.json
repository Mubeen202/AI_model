{
  "requires": [{
    "type": "conda",
    "name": ["ffmpeg", "cmake"],
    "args": "-c conda-forge"
  }, {
    "name": "cuda"
  }],
  "run": [{
    "method": "shell.run",
    "params": {
      "message": "git clone https://github.com/ggerganov/llama.cpp"
    }
  }, {
    "method": "fs.download",
    "params": {
      "uri": "https://huggingface.co/mys/ggml_bakllava-1/resolve/main/ggml-model-q4_k.gguf",
      "dir": "llama.cpp/models"
    }
  }, {
    "method": "fs.download",
    "params": {
      "uri": "https://huggingface.co/mys/ggml_bakllava-1/resolve/main/mmproj-model-f16.gguf",
      "dir": "llama.cpp/models"
    }
  }, {
    "method": "shell.run",
    "params": {
      "message": [
        "mkdir build",
        "cd build",
        "cmake .. -DLLAMA_CUBLAS=ON",
        "cmake --build . --config Release",
        "cd .."
      ],
      "path": "llama.cpp"
    }
  }, {
    "method": "shell.run",
    "params": {
      "venv": "venv",
      "message": "pip install -r requirements.txt"
    }
  }, {
    "method": "input",
    "params": {
      "title": "Install Finished",
      "description": "Go back to the dashboard and launch the app!"
    }
  }, {
    "method": "browser.open",
    "params": {
      "uri": "/?selected=Mirror"
    }
  }]
}
